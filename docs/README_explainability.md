# Explainability and SHAP Integration

## ğŸ¯ Motivation

Transparency is critical for financial models, especially in portfolio risk management. To comply with regulatory demands and improve investor trust, we integrate per-asset interpretability.

---

## ğŸ’¡ SHAP Values

SHAP (SHapley Additive exPlanations) values quantify each assetâ€™s contribution to portfolio tail risk. Based on cooperative game theory, SHAP assigns each feature (asset) a risk contribution score.

---

## ğŸ—ï¸ Implementation

- Uses the SHAP Explainer on per-asset return matrix
- Computes global summary plots to visualize contributions
- Supports local force plots for individual "what-if" scenarios

---

## ğŸ“ˆ Outputs

- Beeswarm summary plot: highlights dominant risk contributors
- Local force plots: explain asset-specific impacts on a single scenario
- Textual summary: "Asset 2 contributes 40% of tail risk; consider reducing allocation"

---

## ğŸ¤– Code Reference

See `app/explain.py` for SHAP integration details and `notebooks/Explainability_Demo.ipynb` for sample plots.

---

## ğŸ“„ References

- Lundberg, S., and Lee, S.-I. (2017). A Unified Approach to Interpreting Model Predictions. NeurIPS.
